{
  "articles": [
    {
      "path": "about.html",
      "title": "Matheus Cordeiro",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Portfolio Website\r\n          \r\n          \r\n          Home\r\n          About\r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Matheus Cordeiro\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                        LinkedIn\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        GitHub\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        Email\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        Tableau\r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n        \r\n        \r\n          \r\n            \r\n            Bio\r\n            Matheus Cordeiro is an international student from Brazil, who is studying his Master in Business Administration at Cal Poly Pomona. With his bachelor’s in Chemical Engineering, he uses his analytical skills, combined with his previous experience in marketing, to provide important and relevant information to the decision-makers.\r\n            At this moment, he is looking to gain professional experience in different types of analytical areas related to data (data analysis, finance analyst, marketing analyst, etc). He has a passion for analyzing data and problem solving, and how it can facilitate innovation.\r\n            \r\n            \r\n            Education\r\n            California Polytechnic State University Pomona | Pomona, CA\r\n            Master in Business Analytics | August 2021 - August 2022 (expected)\r\n            Sao Paulo State University (USP) | Lorena, Brazil\r\n            B.S. in Chemical Engineering | January 2015 - December 2020\r\n            \r\n            \r\n            Experience\r\n            Center for Customer Insights and Digital Marketing | Data Analytics Lead | March 2022 - Present\r\n            Center for Customer Insights and Digital Marketing | Junior Data Scientist | September 2021 - March 2022\r\n            DuPont | Marketing Specialist | January 2021 - July 2021\r\n            DuPont | Marketing Strategy Intern LATAM | January 2020 - December 2020\r\n            BASF | Global Laboratory Intern | August 2018 - December 2019\r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Matheus Cordeiro\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                      LinkedIn\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      Tableau\r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              \r\n              Bio\r\n              Matheus Cordeiro is an international student from Brazil, who is studying his Master in Business Administration at Cal Poly Pomona. With his bachelor’s in Chemical Engineering, he uses his analytical skills, combined with his previous experience in marketing, to provide important and relevant information to the decision-makers.\r\n              At this moment, he is looking to gain professional experience in different types of analytical areas related to data (data analysis, finance analyst, marketing analyst, etc). He has a passion for analyzing data and problem solving, and how it can facilitate innovation.\r\n              \r\n              \r\n              Education\r\n              California Polytechnic State University Pomona | Pomona, CA\r\n              Master in Business Analytics | August 2021 - August 2022 (expected)\r\n              Sao Paulo State University (USP) | Lorena, Brazil\r\n              B.S. in Chemical Engineering | January 2015 - December 2020\r\n              \r\n              \r\n              Experience\r\n              Center for Customer Insights and Digital Marketing | Data Analytics Lead | March 2022 - Present\r\n              Center for Customer Insights and Digital Marketing | Junior Data Scientist | September 2021 - March 2022\r\n              DuPont | Marketing Specialist | January 2021 - July 2021\r\n              DuPont | Marketing Strategy Intern LATAM | January 2020 - December 2020\r\n              BASF | Global Laboratory Intern | August 2018 - December 2019\r\n              \r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2022-03-19T21:07:18-07:00"
    },
    {
      "path": "content.html",
      "title": "Portfolio",
      "description": "Here you will find all my projects displayed! ",
      "author": [],
      "contents": "\r\nPython\r\nSales Analysis\r\nIn this project I used Python Pandas & Python Matplotlib to analyze and answer business questions about 12 months worth of sales data. The data contains hundreds of thousands of electronics store purchases broken down by month, product type, cost, purchase address, etc.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-20T10:38:41-07:00"
    },
    {
      "path": "corr_movie.html",
      "title": "Correlation in Movie Industry",
      "description": "For this project the first questions that came to my mind was: Is the movie industry dying? Is Netflix the new entertainment king? And the best way to answer those is analyzing that dataset of four decades using Pandas, Matpoltlib and Seaborn to also understand more factors that intervene in this industry, like actors, genres, user ratings and more.",
      "author": [],
      "contents": "\r\nImport Libraries\r\n\r\nimport pandas as pd \r\nimport seaborn as sns\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.pyplot import figure\r\nplt.style.use('ggplot')\r\n\r\nLoading data\r\nRead the dataframe and look the data\r\n\r\ndf = pd.read_csv('movies.csv')\r\ndf_head=df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\nreleased\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJune 13, 1980 (United States)\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000.0\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\nUnited Kingdom\r\n\r\n\r\n\r\n19000000.0\r\n\r\n\r\n\r\n46998772.0\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 2, 1980 (United States)\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000.0\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n4500000.0\r\n\r\n\r\n\r\n58853106.0\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJune 20, 1980 (United States)\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000.0\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n18000000.0\r\n\r\n\r\n\r\n538375067.0\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 2, 1980 (United States)\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000.0\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n3500000.0\r\n\r\n\r\n\r\n83453539.0\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 25, 1980 (United States)\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000.0\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n6000000.0\r\n\r\n\r\n\r\n39846344.0\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n’\r\n\r\nCleaning (Pre Prossesing)\r\nWe can see some missing values into df\r\n\r\ndf.isna().sum()\r\nname           0\r\nrating        77\r\ngenre          0\r\nyear           0\r\nreleased       2\r\nscore          3\r\nvotes          3\r\ndirector       0\r\nwriter         3\r\nstar           1\r\ncountry        3\r\nbudget      2171\r\ngross        189\r\ncompany       17\r\nruntime        4\r\ndtype: int64\r\n\r\nLet’s drop all the missing values\r\n\r\ndf.dropna(inplace=True)\r\ndf.isna().sum()\r\nname        0\r\nrating      0\r\ngenre       0\r\nyear        0\r\nreleased    0\r\nscore       0\r\nvotes       0\r\ndirector    0\r\nwriter      0\r\nstar        0\r\ncountry     0\r\nbudget      0\r\ngross       0\r\ncompany     0\r\nruntime     0\r\ndtype: int64\r\n\r\nChecking the Data types for the dataset\r\n\r\ndf.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nInt64Index: 5421 entries, 0 to 7652\r\nData columns (total 15 columns):\r\n #   Column    Non-Null Count  Dtype  \r\n---  ------    --------------  -----  \r\n 0   name      5421 non-null   object \r\n 1   rating    5421 non-null   object \r\n 2   genre     5421 non-null   object \r\n 3   year      5421 non-null   int64  \r\n 4   released  5421 non-null   object \r\n 5   score     5421 non-null   float64\r\n 6   votes     5421 non-null   float64\r\n 7   director  5421 non-null   object \r\n 8   writer    5421 non-null   object \r\n 9   star      5421 non-null   object \r\n 10  country   5421 non-null   object \r\n 11  budget    5421 non-null   float64\r\n 12  gross     5421 non-null   float64\r\n 13  company   5421 non-null   object \r\n 14  runtime   5421 non-null   float64\r\ndtypes: float64(5), int64(1), object(9)\r\nmemory usage: 677.6+ KB\r\n\r\nFor the operations that we going to do here, we need to change the type of the columns “votes”, “budget” and “gross” to integer. Also for the column “released”, we will modify to string to extract the year.\r\n\r\ndf['votes']=df['votes'].astype('int64')\r\ndf['budget']=df['budget'].astype('int64')\r\ndf['gross']=df['gross'].astype('int64')\r\ndf['released']=df['released'].astype('string')\r\ndf.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nInt64Index: 5421 entries, 0 to 7652\r\nData columns (total 15 columns):\r\n #   Column    Non-Null Count  Dtype  \r\n---  ------    --------------  -----  \r\n 0   name      5421 non-null   object \r\n 1   rating    5421 non-null   object \r\n 2   genre     5421 non-null   object \r\n 3   year      5421 non-null   int64  \r\n 4   released  5421 non-null   string \r\n 5   score     5421 non-null   float64\r\n 6   votes     5421 non-null   int64  \r\n 7   director  5421 non-null   object \r\n 8   writer    5421 non-null   object \r\n 9   star      5421 non-null   object \r\n 10  country   5421 non-null   object \r\n 11  budget    5421 non-null   int64  \r\n 12  gross     5421 non-null   int64  \r\n 13  company   5421 non-null   object \r\n 14  runtime   5421 non-null   float64\r\ndtypes: float64(2), int64(4), object(8), string(1)\r\nmemory usage: 677.6+ KB\r\n\r\nLet’s see the movies that expand the most money on\r\n\r\ndf_sort=df.sort_values(by=['gross'],inplace=False,ascending=False)\r\ndf_sort_head=df_sort.head()\r\ndf_sort_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\nreleased\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\n5445\r\n\r\n\r\n\r\nAvatar\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n2009\r\n\r\n\r\n\r\nDecember 18, 2009 (United States)\r\n\r\n\r\n\r\n7.8\r\n\r\n\r\n\r\n1100000\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nSam Worthington\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n237000000\r\n\r\n\r\n\r\n2847246203\r\n\r\n\r\n\r\nTwentieth Century Fox\r\n\r\n\r\n\r\n162.0\r\n\r\n\r\n\r\n7445\r\n\r\n\r\n\r\nAvengers: Endgame\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n2019\r\n\r\n\r\n\r\nApril 26, 2019 (United States)\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n903000\r\n\r\n\r\n\r\nAnthony Russo\r\n\r\n\r\n\r\nChristopher Markus\r\n\r\n\r\n\r\nRobert Downey Jr.\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n356000000\r\n\r\n\r\n\r\n2797501328\r\n\r\n\r\n\r\nMarvel Studios\r\n\r\n\r\n\r\n181.0\r\n\r\n\r\n\r\n3045\r\n\r\n\r\n\r\nTitanic\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n1997\r\n\r\n\r\n\r\nDecember 19, 1997 (United States)\r\n\r\n\r\n\r\n7.8\r\n\r\n\r\n\r\n1100000\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nLeonardo DiCaprio\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n200000000\r\n\r\n\r\n\r\n2201647264\r\n\r\n\r\n\r\nTwentieth Century Fox\r\n\r\n\r\n\r\n194.0\r\n\r\n\r\n\r\n6663\r\n\r\n\r\n\r\nStar Wars: Episode VII - The Force Awakens\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n2015\r\n\r\n\r\n\r\nDecember 18, 2015 (United States)\r\n\r\n\r\n\r\n7.8\r\n\r\n\r\n\r\n876000\r\n\r\n\r\n\r\nJ.J. Abrams\r\n\r\n\r\n\r\nLawrence Kasdan\r\n\r\n\r\n\r\nDaisy Ridley\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n245000000\r\n\r\n\r\n\r\n2069521700\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n138.0\r\n\r\n\r\n\r\n7244\r\n\r\n\r\n\r\nAvengers: Infinity War\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n2018\r\n\r\n\r\n\r\nApril 27, 2018 (United States)\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n897000\r\n\r\n\r\n\r\nAnthony Russo\r\n\r\n\r\n\r\nChristopher Markus\r\n\r\n\r\n\r\nRobert Downey Jr.\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n321000000\r\n\r\n\r\n\r\n2048359754\r\n\r\n\r\n\r\nMarvel Studios\r\n\r\n\r\n\r\n149.0\r\n\r\n\r\n’\r\n\r\nFeaturing Engineering\r\nSplitting the column to extract the year and country, by creating other dataframe\r\n\r\nreleased_df=df['released'].str.split(\",\",n = 1,expand = True) \r\nreleased_df.head()\r\n         0                      1\r\n0  June 13   1980 (United States)\r\n1   July 2   1980 (United States)\r\n2  June 20   1980 (United States)\r\n3   July 2   1980 (United States)\r\n4  July 25   1980 (United States)\r\n\r\n\r\ndf['Day_Month']=released_df[0]\r\ndf['Year_Correct']=released_df[1].str[:5]\r\ndf['Country_Correct']=released_df[1].str[5:]\r\ndf['Country_Correct']=df['Country_Correct'].str[2:-1]\r\n\r\nNow we can see looking the column “released” that the year and the country are correct\r\n\r\ndf_head=df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\nreleased\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nDay_Month\r\n\r\n\r\n\r\nYear_Correct\r\n\r\n\r\n\r\nCountry_Correct\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJune 13, 1980 (United States)\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\nUnited Kingdom\r\n\r\n\r\n\r\n19000000\r\n\r\n\r\n\r\n46998772\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\nJune 13\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 2, 1980 (United States)\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n4500000\r\n\r\n\r\n\r\n58853106\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\nJuly 2\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJune 20, 1980 (United States)\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n18000000\r\n\r\n\r\n\r\n538375067\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\nJune 20\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 2, 1980 (United States)\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n3500000\r\n\r\n\r\n\r\n83453539\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\nJuly 2\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 25, 1980 (United States)\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n6000000\r\n\r\n\r\n\r\n39846344\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n\r\nJuly 25\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n’\r\n\r\nCreating other 2 columns for month and day\r\n\r\nday_month=df['Day_Month'].str.split(\" \",n = 1,expand = True) \r\ndf['Month']=day_month[0]\r\ndf['Day']=day_month[1]\r\ndf_head=df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\nreleased\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nDay_Month\r\n\r\n\r\n\r\nYear_Correct\r\n\r\n\r\n\r\nCountry_Correct\r\n\r\n\r\n\r\nMonth\r\n\r\n\r\n\r\nDay\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJune 13, 1980 (United States)\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\nUnited Kingdom\r\n\r\n\r\n\r\n19000000\r\n\r\n\r\n\r\n46998772\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\nJune 13\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n13\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 2, 1980 (United States)\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n4500000\r\n\r\n\r\n\r\n58853106\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\nJuly 2\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJune 20, 1980 (United States)\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n18000000\r\n\r\n\r\n\r\n538375067\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\nJune 20\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n20\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 2, 1980 (United States)\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n3500000\r\n\r\n\r\n\r\n83453539\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\nJuly 2\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nJuly 25, 1980 (United States)\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\n6000000\r\n\r\n\r\n\r\n39846344\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n\r\nJuly 25\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n25\r\n\r\n\r\n’\r\n\r\nDropping the columns that we don’t need anymore\r\n\r\ndf.drop(['year','released','Day_Month','country'],axis=1,inplace=True)\r\ndf_head=df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nYear_Correct\r\n\r\n\r\n\r\nCountry_Correct\r\n\r\n\r\n\r\nMonth\r\n\r\n\r\n\r\nDay\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\n19000000\r\n\r\n\r\n\r\n46998772\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n13\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\n4500000\r\n\r\n\r\n\r\n58853106\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\n18000000\r\n\r\n\r\n\r\n538375067\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n20\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\n3500000\r\n\r\n\r\n\r\n83453539\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\n6000000\r\n\r\n\r\n\r\n39846344\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n25\r\n\r\n\r\n’\r\n\r\nFor a better undestand, let’s renema some columns\r\n\r\ndf.rename(columns={\"Year_Correct\": \"year\", \"Country_Correct\": \"country\",'Month':'month','Day':'day'},inplace=True)\r\ndf_head=df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nmonth\r\n\r\n\r\n\r\nday\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\n19000000\r\n\r\n\r\n\r\n46998772\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n13\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\n4500000\r\n\r\n\r\n\r\n58853106\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\n18000000\r\n\r\n\r\n\r\n538375067\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n20\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\n3500000\r\n\r\n\r\n\r\n83453539\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\n6000000\r\n\r\n\r\n\r\n39846344\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n25\r\n\r\n\r\n’\r\n\r\n\r\ndf_sorted = df.sort_values(by=['gross'],inplace=False,ascending=False)\r\ndf_sorted_head=df_sorted.head()\r\ndf_sorted_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nmonth\r\n\r\n\r\n\r\nday\r\n\r\n\r\n\r\n5445\r\n\r\n\r\n\r\nAvatar\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n7.8\r\n\r\n\r\n\r\n1100000\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nSam Worthington\r\n\r\n\r\n\r\n237000000\r\n\r\n\r\n\r\n2847246203\r\n\r\n\r\n\r\nTwentieth Century Fox\r\n\r\n\r\n\r\n162.0\r\n\r\n\r\n\r\n2009\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nDecember\r\n\r\n\r\n\r\n18\r\n\r\n\r\n\r\n7445\r\n\r\n\r\n\r\nAvengers: Endgame\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n903000\r\n\r\n\r\n\r\nAnthony Russo\r\n\r\n\r\n\r\nChristopher Markus\r\n\r\n\r\n\r\nRobert Downey Jr.\r\n\r\n\r\n\r\n356000000\r\n\r\n\r\n\r\n2797501328\r\n\r\n\r\n\r\nMarvel Studios\r\n\r\n\r\n\r\n181.0\r\n\r\n\r\n\r\n2019\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nApril\r\n\r\n\r\n\r\n26\r\n\r\n\r\n\r\n3045\r\n\r\n\r\n\r\nTitanic\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n7.8\r\n\r\n\r\n\r\n1100000\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nJames Cameron\r\n\r\n\r\n\r\nLeonardo DiCaprio\r\n\r\n\r\n\r\n200000000\r\n\r\n\r\n\r\n2201647264\r\n\r\n\r\n\r\nTwentieth Century Fox\r\n\r\n\r\n\r\n194.0\r\n\r\n\r\n\r\n1997\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nDecember\r\n\r\n\r\n\r\n19\r\n\r\n\r\n\r\n6663\r\n\r\n\r\n\r\nStar Wars: Episode VII - The Force Awakens\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n7.8\r\n\r\n\r\n\r\n876000\r\n\r\n\r\n\r\nJ.J. Abrams\r\n\r\n\r\n\r\nLawrence Kasdan\r\n\r\n\r\n\r\nDaisy Ridley\r\n\r\n\r\n\r\n245000000\r\n\r\n\r\n\r\n2069521700\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n138.0\r\n\r\n\r\n\r\n2015\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nDecember\r\n\r\n\r\n\r\n18\r\n\r\n\r\n\r\n7244\r\n\r\n\r\n\r\nAvengers: Infinity War\r\n\r\n\r\n\r\nPG-13\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n897000\r\n\r\n\r\n\r\nAnthony Russo\r\n\r\n\r\n\r\nChristopher Markus\r\n\r\n\r\n\r\nRobert Downey Jr.\r\n\r\n\r\n\r\n321000000\r\n\r\n\r\n\r\n2048359754\r\n\r\n\r\n\r\nMarvel Studios\r\n\r\n\r\n\r\n149.0\r\n\r\n\r\n\r\n2018\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nApril\r\n\r\n\r\n\r\n27\r\n\r\n\r\n’\r\n\r\nDropping any duplicates and change the type of the column “year” (that we have just created) to numeric\r\n\r\ndf_drop=df.drop_duplicates().head()\r\ndf_drop.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nmonth\r\n\r\n\r\n\r\nday\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\n19000000\r\n\r\n\r\n\r\n46998772\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n13\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\n4500000\r\n\r\n\r\n\r\n58853106\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\n18000000\r\n\r\n\r\n\r\n538375067\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n20\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\n3500000\r\n\r\n\r\n\r\n83453539\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\n6000000\r\n\r\n\r\n\r\n39846344\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n\r\n1980\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n25\r\n\r\n\r\n’\r\ndf['year']=pd.to_numeric(df['year'])\r\n\r\nHyphotesis\r\nWe going to start the make hypothesis about correlations in our dataframe. First, last assume that the column “gross” and “budget” are positive correlated and let’s see if this is true\r\nCorrelation between Gross and Budget\r\nLet’s plot a Scatter plot to compare those two variables\r\n\r\nsns.regplot(data=df,x='gross',y='budget',color=\"b\",line_kws={\"color\":\"red\"});\r\nplt.title(\"Gross Vs Budget Earnings\");\r\nplt.xlabel(\"Gross Earnings\");\r\nplt.ylabel(\"Budget for Film\");\r\nplt.show()\r\n\r\n\r\nHeat Map\r\nLet’s look to see if we can find other correlation\r\n\r\ncorr_matrix=df.corr()\r\nsns.heatmap(corr_matrix,annot=True);\r\nplt.title(\"Correlation Matrix between Numeric Features\");\r\nplt.xlabel(\"Movies Features\");\r\nplt.ylabel(\"Movies Features\");\r\nplt.show()\r\n\r\n\r\nCorrelation between Gross and Number of Votes\r\nSeems that gross and votes are correlated as well, so let’s plot a regression too.\r\n\r\nsns.regplot(data=df,x='gross',y='votes',color=\"b\",line_kws={\"color\":\"red\"});\r\nplt.title(\"Gross Vs Number of Votes\");\r\nplt.xlabel(\"Gross Earnings\");\r\nplt.ylabel(\"Votes\");\r\nplt.show()\r\n\r\n\r\nChi Square Test\r\nLet’s run another test, this time is the Chi Square test between 2 categorical variables: rating and genre\r\nOur null hypothesis is: Rating and Genre are independent and our level of confidence will be 95%\r\n\r\ncontigency=pd.crosstab(df['rating'],df['genre'])\r\ncont=contigency.head()\r\ncont.to_html()\r\n’\r\n\r\ngenre\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\nAnimation\r\n\r\n\r\n\r\nBiography\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\nCrime\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\nFamily\r\n\r\n\r\n\r\nFantasy\r\n\r\n\r\n\r\nHorror\r\n\r\n\r\n\r\nMystery\r\n\r\n\r\n\r\nRomance\r\n\r\n\r\n\r\nSci-Fi\r\n\r\n\r\n\r\nThriller\r\n\r\n\r\n\r\nWestern\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nApproved\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nG\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n13\r\n\r\n\r\n\r\n82\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n11\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nNC-17\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n6\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nNot Rated\r\n\r\n\r\n\r\n5\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n6\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n20\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\n146\r\n\r\n\r\n\r\n166\r\n\r\n\r\n\r\n175\r\n\r\n\r\n\r\n46\r\n\r\n\r\n\r\n275\r\n\r\n\r\n\r\n5\r\n\r\n\r\n\r\n77\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n5\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n1\r\n\r\n\r\n’\r\n\r\nThe p-value below 0, which means that we do not reject the null hypothesis at 95% level of confidence\r\n\r\nfrom scipy.stats import chi2_contingency\r\nc, p, dof, expected = chi2_contingency(contigency)\r\np\r\n0.0\r\n\r\nExtra\r\nHere will fing correlation between categorical variable with some numerical ones.\r\nFirst, we will create a copy of df. After, change the type of “rating” and “genre” to category\r\n\r\ndf1 = df.copy()\r\ndf1['rating']=df1['rating'].astype('category')\r\ndf1['genre']=df1['genre'].astype('category')\r\ndf1.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nInt64Index: 5421 entries, 0 to 7652\r\nData columns (total 16 columns):\r\n #   Column    Non-Null Count  Dtype   \r\n---  ------    --------------  -----   \r\n 0   name      5421 non-null   object  \r\n 1   rating    5421 non-null   category\r\n 2   genre     5421 non-null   category\r\n 3   score     5421 non-null   float64 \r\n 4   votes     5421 non-null   int64   \r\n 5   director  5421 non-null   object  \r\n 6   writer    5421 non-null   object  \r\n 7   star      5421 non-null   object  \r\n 8   budget    5421 non-null   int64   \r\n 9   gross     5421 non-null   int64   \r\n 10  company   5421 non-null   object  \r\n 11  runtime   5421 non-null   float64 \r\n 12  year      5407 non-null   float64 \r\n 13  country   5407 non-null   string  \r\n 14  month     5421 non-null   string  \r\n 15  day       5421 non-null   string  \r\ndtypes: category(2), float64(3), int64(3), object(5), string(3)\r\nmemory usage: 646.9+ KB\r\n\r\nWith this type of data type, we are able to genereate categories codes for categorical variables\r\n\r\ndf1['rating_cat']=df1['rating'].cat.codes\r\ndf1['genre_cat']=df1['genre'].cat.codes\r\ndf1_head=df1.head()\r\ndf1_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\n\r\nrating\r\n\r\n\r\n\r\ngenre\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\ndirector\r\n\r\n\r\n\r\nwriter\r\n\r\n\r\n\r\nstar\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\ncompany\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\ncountry\r\n\r\n\r\n\r\nmonth\r\n\r\n\r\n\r\nday\r\n\r\n\r\n\r\nrating_cat\r\n\r\n\r\n\r\ngenre_cat\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\nThe Shining\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nDrama\r\n\r\n\r\n\r\n8.4\r\n\r\n\r\n\r\n927000\r\n\r\n\r\n\r\nStanley Kubrick\r\n\r\n\r\n\r\nStephen King\r\n\r\n\r\n\r\nJack Nicholson\r\n\r\n\r\n\r\n19000000\r\n\r\n\r\n\r\n46998772\r\n\r\n\r\n\r\nWarner Bros.\r\n\r\n\r\n\r\n146.0\r\n\r\n\r\n\r\n1980.0\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n13\r\n\r\n\r\n\r\n6\r\n\r\n\r\n\r\n6\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\nThe Blue Lagoon\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nAdventure\r\n\r\n\r\n\r\n5.8\r\n\r\n\r\n\r\n65000\r\n\r\n\r\n\r\nRandal Kleiser\r\n\r\n\r\n\r\nHenry De Vere Stacpoole\r\n\r\n\r\n\r\nBrooke Shields\r\n\r\n\r\n\r\n4500000\r\n\r\n\r\n\r\n58853106\r\n\r\n\r\n\r\nColumbia Pictures\r\n\r\n\r\n\r\n104.0\r\n\r\n\r\n\r\n1980.0\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n6\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\nStar Wars: Episode V - The Empire Strikes Back\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nAction\r\n\r\n\r\n\r\n8.7\r\n\r\n\r\n\r\n1200000\r\n\r\n\r\n\r\nIrvin Kershner\r\n\r\n\r\n\r\nLeigh Brackett\r\n\r\n\r\n\r\nMark Hamill\r\n\r\n\r\n\r\n18000000\r\n\r\n\r\n\r\n538375067\r\n\r\n\r\n\r\nLucasfilm\r\n\r\n\r\n\r\n124.0\r\n\r\n\r\n\r\n1980.0\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJune\r\n\r\n\r\n\r\n20\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\nAirplane!\r\n\r\n\r\n\r\nPG\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.7\r\n\r\n\r\n\r\n221000\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nJim Abrahams\r\n\r\n\r\n\r\nRobert Hays\r\n\r\n\r\n\r\n3500000\r\n\r\n\r\n\r\n83453539\r\n\r\n\r\n\r\nParamount Pictures\r\n\r\n\r\n\r\n88.0\r\n\r\n\r\n\r\n1980.0\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\nCaddyshack\r\n\r\n\r\n\r\nR\r\n\r\n\r\n\r\nComedy\r\n\r\n\r\n\r\n7.3\r\n\r\n\r\n\r\n108000\r\n\r\n\r\n\r\nHarold Ramis\r\n\r\n\r\n\r\nBrian Doyle-Murray\r\n\r\n\r\n\r\nChevy Chase\r\n\r\n\r\n\r\n6000000\r\n\r\n\r\n\r\n39846344\r\n\r\n\r\n\r\nOrion Pictures\r\n\r\n\r\n\r\n98.0\r\n\r\n\r\n\r\n1980.0\r\n\r\n\r\n\r\nUnited States\r\n\r\n\r\n\r\nJuly\r\n\r\n\r\n\r\n25\r\n\r\n\r\n\r\n6\r\n\r\n\r\n\r\n4\r\n\r\n\r\n’\r\n\r\nCorrelation in df1\r\n\r\ndf1_corr=df1.corr()\r\ndf1_corr.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\nrating_cat\r\n\r\n\r\n\r\ngenre_cat\r\n\r\n\r\n\r\nscore\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.474256\r\n\r\n\r\n\r\n0.072001\r\n\r\n\r\n\r\n0.222556\r\n\r\n\r\n\r\n0.414068\r\n\r\n\r\n\r\n0.061443\r\n\r\n\r\n\r\n0.065983\r\n\r\n\r\n\r\n0.035106\r\n\r\n\r\n\r\nvotes\r\n\r\n\r\n\r\n0.474256\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.439675\r\n\r\n\r\n\r\n0.614751\r\n\r\n\r\n\r\n0.352303\r\n\r\n\r\n\r\n0.202215\r\n\r\n\r\n\r\n0.006031\r\n\r\n\r\n\r\n-0.135990\r\n\r\n\r\n\r\nbudget\r\n\r\n\r\n\r\n0.072001\r\n\r\n\r\n\r\n0.439675\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.740247\r\n\r\n\r\n\r\n0.318695\r\n\r\n\r\n\r\n0.319669\r\n\r\n\r\n\r\n-0.203946\r\n\r\n\r\n\r\n-0.368523\r\n\r\n\r\n\r\ngross\r\n\r\n\r\n\r\n0.222556\r\n\r\n\r\n\r\n0.614751\r\n\r\n\r\n\r\n0.740247\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.275796\r\n\r\n\r\n\r\n0.268141\r\n\r\n\r\n\r\n-0.181906\r\n\r\n\r\n\r\n-0.244101\r\n\r\n\r\n\r\nruntime\r\n\r\n\r\n\r\n0.414068\r\n\r\n\r\n\r\n0.352303\r\n\r\n\r\n\r\n0.318695\r\n\r\n\r\n\r\n0.275796\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.075183\r\n\r\n\r\n\r\n0.140792\r\n\r\n\r\n\r\n-0.059237\r\n\r\n\r\n\r\nyear\r\n\r\n\r\n\r\n0.061443\r\n\r\n\r\n\r\n0.202215\r\n\r\n\r\n\r\n0.319669\r\n\r\n\r\n\r\n0.268141\r\n\r\n\r\n\r\n0.075183\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.022089\r\n\r\n\r\n\r\n-0.066049\r\n\r\n\r\n\r\nrating_cat\r\n\r\n\r\n\r\n0.065983\r\n\r\n\r\n\r\n0.006031\r\n\r\n\r\n\r\n-0.203946\r\n\r\n\r\n\r\n-0.181906\r\n\r\n\r\n\r\n0.140792\r\n\r\n\r\n\r\n0.022089\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n\r\n0.147796\r\n\r\n\r\n\r\ngenre_cat\r\n\r\n\r\n\r\n0.035106\r\n\r\n\r\n\r\n-0.135990\r\n\r\n\r\n\r\n-0.368523\r\n\r\n\r\n\r\n-0.244101\r\n\r\n\r\n\r\n-0.059237\r\n\r\n\r\n\r\n-0.066049\r\n\r\n\r\n\r\n0.147796\r\n\r\n\r\n\r\n1.000000\r\n\r\n\r\n’\r\n\r\nIn df2, will contain the dummies of rating and genre.\r\n\r\ndf2=pd.get_dummies(df1,columns=['rating','genre']).head()\r\n\r\nFinding the highest correlation\r\n\r\ndf2_matrix=df2.corr()\r\ncorr_pairs = df2_matrix.unstack()\r\nsorted_pairs = corr_pairs.sort_values()\r\nsorted_pairs.dropna()\r\nrating_R         rating_PG      -1.000000\r\nrating_PG        rating_cat     -1.000000\r\n                 rating_R       -1.000000\r\nrating_cat       rating_PG      -1.000000\r\ngenre_Adventure  score          -0.873726\r\n                                   ...   \r\ngross            gross           1.000000\r\nbudget           budget          1.000000\r\nvotes            votes           1.000000\r\ngenre_Comedy     genre_Comedy    1.000000\r\ngenre_Drama      genre_Drama     1.000000\r\nLength: 169, dtype: float64\r\nhigh_corr = sorted_pairs[(sorted_pairs)>0.7]\r\nhigh_corr\r\nvotes            gross              0.729639\r\ngross            votes              0.729639\r\nvotes            genre_Action       0.744107\r\ngenre_Action     votes              0.744107\r\nbudget           score              0.760846\r\nscore            budget             0.760846\r\nruntime          votes              0.798509\r\nvotes            runtime            0.798509\r\nruntime          genre_Drama        0.822495\r\ngenre_Drama      runtime            0.822495\r\nvotes            score              0.833480\r\nscore            votes              0.833480\r\nruntime          budget             0.932112\r\nbudget           runtime            0.932112\r\n                 votes              0.952681\r\nvotes            budget             0.952681\r\ngross            genre_Action       0.997050\r\ngenre_Action     gross              0.997050\r\nscore            score              1.000000\r\ngenre_cat        genre_cat          1.000000\r\ngenre_Adventure  genre_Adventure    1.000000\r\ngenre_Action     genre_Action       1.000000\r\nrating_R         rating_R           1.000000\r\n                 rating_cat         1.000000\r\nrating_PG        rating_PG          1.000000\r\nrating_cat       rating_R           1.000000\r\n                 rating_cat         1.000000\r\nruntime          runtime            1.000000\r\ngross            gross              1.000000\r\nbudget           budget             1.000000\r\nvotes            votes              1.000000\r\ngenre_Comedy     genre_Comedy       1.000000\r\ngenre_Drama      genre_Drama        1.000000\r\ndtype: float64\r\n\r\nConclusions\r\nFor the correlation above, we can conclude that the genre Action have a very high correlation with gross, therefore those who are looking for profit when thinking about make a movies, this a excellent genre to plan. Also, the drama genre is the one which have the highest correlation with run time. We can conclude that films with lower duration are not well accpeted by those who love drama films.\r\nThank you!\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-20T11:13:03-07:00"
    },
    {
      "path": "index.html",
      "title": "Portfolio Website",
      "description": "Welcome to the website. I hope you enjoy it!\n",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-19T21:07:20-07:00"
    },
    {
      "path": "sales_analysis.html",
      "title": "Sales Analysis",
      "description": "In this project I used Python Pandas & Python Matplotlib to analyze and answer business questions about 12 months worth of sales data. The data contains hundreds of thousands of electronics store purchases broken down by month, product type, cost, purchase address, etc.",
      "author": [],
      "contents": "\r\nImport Libraries\r\n\r\nimport pandas as pd \r\nimport seaborn as sns\r\nimport matplotlib.pyplot as plt\r\nfrom matplotlib.pyplot import figure\r\nfrom itertools import combinations \r\nfrom collections import Counter\r\n\r\nLoading data\r\n\r\njan = pd.read_csv(\"Sales_January_2019.csv\")\r\nfeb = pd.read_csv(\"Sales_February_2019.csv\")\r\nmar = pd.read_csv(\"Sales_March_2019.csv\")\r\napr = pd.read_csv(\"Sales_April_2019.csv\")\r\nmay = pd.read_csv(\"Sales_May_2019.csv\")\r\njun = pd.read_csv(\"Sales_June_2019.csv\")\r\njul = pd.read_csv(\"Sales_July_2019.csv\")\r\naug = pd.read_csv(\"Sales_August_2019.csv\")\r\nsep = pd.read_csv(\"Sales_September_2019.csv\")\r\nocto = pd.read_csv(\"Sales_October_2019.csv\")\r\nnov = pd.read_csv(\"Sales_November_2019.csv\")\r\ndec = pd.read_csv(\"Sales_December_2019.csv\")\r\n\r\nFirst look\r\n\r\njan_head=jan.head()\r\njan_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n141234\r\n\r\n\r\n\r\niPhone\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n700\r\n\r\n\r\n\r\n01/22/19 21:25\r\n\r\n\r\n\r\n944 Walnut St, Boston, MA 02215\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n141235\r\n\r\n\r\n\r\nLightning Charging Cable\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n01/28/19 14:15\r\n\r\n\r\n\r\n185 Maple St, Portland, OR 97035\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n141236\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/17/19 13:33\r\n\r\n\r\n\r\n538 Adams St, San Francisco, CA 94016\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n141237\r\n\r\n\r\n\r\n27in FHD Monitor\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n149.99\r\n\r\n\r\n\r\n01/05/19 20:33\r\n\r\n\r\n\r\n738 10th St, Los Angeles, CA 90001\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n141238\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/25/19 11:59\r\n\r\n\r\n\r\n387 10th St, Austin, TX 73301\r\n\r\n\r\n’\r\nfeb_head=feb.head()\r\nfeb_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n150502\r\n\r\n\r\n\r\niPhone\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n700\r\n\r\n\r\n\r\n02/18/19 01:35\r\n\r\n\r\n\r\n866 Spruce St, Portland, ME 04101\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n150503\r\n\r\n\r\n\r\nAA Batteries (4-pack)\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n3.84\r\n\r\n\r\n\r\n02/13/19 07:24\r\n\r\n\r\n\r\n18 13th St, San Francisco, CA 94016\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n150504\r\n\r\n\r\n\r\n27in 4K Gaming Monitor\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n389.99\r\n\r\n\r\n\r\n02/18/19 09:46\r\n\r\n\r\n\r\n52 6th St, New York City, NY 10001\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n150505\r\n\r\n\r\n\r\nLightning Charging Cable\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n02/02/19 16:47\r\n\r\n\r\n\r\n129 Cherry St, Atlanta, GA 30301\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n150506\r\n\r\n\r\n\r\nAA Batteries (4-pack)\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n3.84\r\n\r\n\r\n\r\n02/28/19 20:32\r\n\r\n\r\n\r\n548 Lincoln St, Seattle, WA 98101\r\n\r\n\r\n’\r\nmar_head=mar.head()\r\nmar_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n162009\r\n\r\n\r\n\r\niPhone\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n700\r\n\r\n\r\n\r\n03/28/19 20:59\r\n\r\n\r\n\r\n942 Church St, Austin, TX 73301\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n162009\r\n\r\n\r\n\r\nLightning Charging Cable\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n03/28/19 20:59\r\n\r\n\r\n\r\n942 Church St, Austin, TX 73301\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n162009\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n03/28/19 20:59\r\n\r\n\r\n\r\n942 Church St, Austin, TX 73301\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n162010\r\n\r\n\r\n\r\nBose SoundSport Headphones\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n99.99\r\n\r\n\r\n\r\n03/17/19 05:39\r\n\r\n\r\n\r\n261 10th St, San Francisco, CA 94016\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n162011\r\n\r\n\r\n\r\n34in Ultrawide Monitor\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n379.99\r\n\r\n\r\n\r\n03/10/19 00:01\r\n\r\n\r\n\r\n764 13th St, San Francisco, CA 94016\r\n\r\n\r\n’\r\n\r\nMerging all the dataset into one single file\r\nIt’s looks like we have the same number of columns in each dataset. Let’s concatenate all of them\r\n\r\n\r\ndf = pd.concat([jan,feb,mar,apr,may,jun,jul,aug,sep,octo,nov,dec])\r\ndf_head = df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n141234\r\n\r\n\r\n\r\niPhone\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n700\r\n\r\n\r\n\r\n01/22/19 21:25\r\n\r\n\r\n\r\n944 Walnut St, Boston, MA 02215\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n141235\r\n\r\n\r\n\r\nLightning Charging Cable\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n01/28/19 14:15\r\n\r\n\r\n\r\n185 Maple St, Portland, OR 97035\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n141236\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/17/19 13:33\r\n\r\n\r\n\r\n538 Adams St, San Francisco, CA 94016\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n141237\r\n\r\n\r\n\r\n27in FHD Monitor\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n149.99\r\n\r\n\r\n\r\n01/05/19 20:33\r\n\r\n\r\n\r\n738 10th St, Los Angeles, CA 90001\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n141238\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/25/19 11:59\r\n\r\n\r\n\r\n387 10th St, Austin, TX 73301\r\n\r\n\r\n’\r\n\r\nLet’s check the shape of it\r\n\r\ndf.shape  #Looks good\r\n(186850, 6)\r\n\r\nQuestions\r\nTo perform our analysis in this dataset I’ll analyze and do the data cleaning within the questions that I want to answer.\r\nQuestion 1: Whats was the best month for sales? How much was earned that month?\r\nWe must check the dtypes of our data first:\r\n\r\ndf.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nInt64Index: 186850 entries, 0 to 25116\r\nData columns (total 6 columns):\r\n #   Column            Non-Null Count   Dtype \r\n---  ------            --------------   ----- \r\n 0   Order ID          186305 non-null  object\r\n 1   Product           186305 non-null  object\r\n 2   Quantity Ordered  186305 non-null  object\r\n 3   Price Each        186305 non-null  object\r\n 4   Order Date        186305 non-null  object\r\n 5   Purchase Address  186305 non-null  object\r\ndtypes: object(6)\r\nmemory usage: 10.0+ MB\r\n\r\nWe’ll collect the first 2 characters of the column “Order Date” but first we need to transform this column to string type\r\n\r\ndf['Order Date']=df['Order Date'].astype('string')\r\n\r\nNow, we can see that the column “Order Date” changed to “string”\r\n\r\ndf.info()\r\n<class 'pandas.core.frame.DataFrame'>\r\nInt64Index: 186850 entries, 0 to 25116\r\nData columns (total 6 columns):\r\n #   Column            Non-Null Count   Dtype \r\n---  ------            --------------   ----- \r\n 0   Order ID          186305 non-null  object\r\n 1   Product           186305 non-null  object\r\n 2   Quantity Ordered  186305 non-null  object\r\n 3   Price Each        186305 non-null  object\r\n 4   Order Date        186305 non-null  string\r\n 5   Purchase Address  186305 non-null  object\r\ndtypes: object(5), string(1)\r\nmemory usage: 10.0+ MB\r\n\r\n\r\ndf[\"Order Date\"]=df[\"Order Date\"].str.replace(\"'\",\"\")\r\ndf[\"Order Date\"]=df[\"Order Date\"].str.replace(\"b\",\"\")\r\n\r\nCreating a column named “Month”\r\n\r\ndf[\"Month\"]=df[\"Order Date\"].str[:2]\r\n\r\nCreating a dictionary to replace the month numbers’s to the respective month\r\n\r\nmonth_dict = {\"01\":\"January\",\"02\":\"February\",\"03\":\"March\",\"04\":\"April\",\"05\":\"May\",\"06\":\"June\",\"07\":\"July\",\r\n             \"08\":\"August\",\"09\":\"September\",\"10\":\"October\",\"11\":\"November\",\"12\":\"December\"}\r\n\r\n\r\ndf[\"Month\"]=df[\"Month\"].replace(month_dict)\r\n\r\nModify the data type to numeric\r\n\r\ndf[\"Price Each\"]=pd.to_numeric(df[\"Price Each\"],errors='coerce')\r\ndf[\"Quantity Ordered\"]=pd.to_numeric(df[\"Quantity Ordered\"],errors='coerce')\r\n\r\nDropping the missing values in our dataset\r\n\r\ndf=df.dropna()\r\n\r\nCreating new column that corresponds to the total sales\r\n\r\ndf[\"Total_Sales\"] = df[\"Price Each\"]*df[\"Quantity Ordered\"]\r\ndf_head = df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\nMonth\r\n\r\n\r\n\r\nTotal_Sales\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n141234\r\n\r\n\r\n\r\niPhone\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n700.00\r\n\r\n\r\n\r\n01/22/19 21:25\r\n\r\n\r\n\r\n944 Walnut St, Boston, MA 02215\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n700.00\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n141235\r\n\r\n\r\n\r\nLightning Charging Cable\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n01/28/19 14:15\r\n\r\n\r\n\r\n185 Maple St, Portland, OR 97035\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n141236\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n2.0\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/17/19 13:33\r\n\r\n\r\n\r\n538 Adams St, San Francisco, CA 94016\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n23.98\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n141237\r\n\r\n\r\n\r\n27in FHD Monitor\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n149.99\r\n\r\n\r\n\r\n01/05/19 20:33\r\n\r\n\r\n\r\n738 10th St, Los Angeles, CA 90001\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n149.99\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n141238\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/25/19 11:59\r\n\r\n\r\n\r\n387 10th St, Austin, TX 73301\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n’\r\n\r\nCreating a new variable to assign the month grouped\r\n\r\nbest_month=df.groupby([\"Month\"]).sum()\r\nbest_month.reset_index(inplace=True)\r\nbest_month\r\n        Month  Quantity Ordered  Price Each  Total_Sales\r\n0       April           20558.0  3367671.02   3390670.24\r\n1      August           13448.0  2230345.42   2244467.88\r\n2    December           28114.0  4588415.41   4613443.34\r\n3    February           13449.0  2188884.72   2202022.42\r\n4     January           10903.0  1811768.38   1822256.73\r\n5        July           16072.0  2632539.56   2647775.76\r\n6        June           15253.0  2562025.61   2577802.26\r\n7       March           17005.0  2791207.83   2807100.38\r\n8         May           18667.0  3135125.13   3152606.75\r\n9    November           19798.0  3180600.68   3199603.20\r\n10    October           22703.0  3715554.83   3736726.88\r\n11  September           13109.0  2084992.09   2097560.13\r\n\r\nPloting the data using seaborn\r\n\r\nsns.barplot(x=\"Total_Sales\", y=\"Month\", data=best_month);\r\nplt.show()\r\n\r\n\r\nDecember was the best month for sales. The total earned this month was $4.613.443,34.\r\nQuestion 2: What city had the highest number of sales?\r\nChanging the datatype on the column “Purchase Address”\r\n\r\ndf[\"Purchase Address\"]=df[\"Purchase Address\"].astype('string')\r\n\r\nCreating a new variable thats contains the city code\r\n\r\ncity=df[\"Purchase Address\"].str.split(pat=\",\",expand=True)\r\n\r\nCreating a new colunm to assign the values from the cities\r\n\r\ndf[\"City\"]=city[1]\r\n\r\nLet´s check how our df looks like now\r\n\r\ndf_head = df.head()\r\ndf_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\nMonth\r\n\r\n\r\n\r\nTotal_Sales\r\n\r\n\r\n\r\nCity\r\n\r\n\r\n\r\n0\r\n\r\n\r\n\r\n141234\r\n\r\n\r\n\r\niPhone\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n700.00\r\n\r\n\r\n\r\n01/22/19 21:25\r\n\r\n\r\n\r\n944 Walnut St, Boston, MA 02215\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n700.00\r\n\r\n\r\n\r\nBoston\r\n\r\n\r\n\r\n1\r\n\r\n\r\n\r\n141235\r\n\r\n\r\n\r\nLightning Charging Cable\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\n01/28/19 14:15\r\n\r\n\r\n\r\n185 Maple St, Portland, OR 97035\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n14.95\r\n\r\n\r\n\r\nPortland\r\n\r\n\r\n\r\n2\r\n\r\n\r\n\r\n141236\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n2.0\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/17/19 13:33\r\n\r\n\r\n\r\n538 Adams St, San Francisco, CA 94016\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n23.98\r\n\r\n\r\n\r\nSan Francisco\r\n\r\n\r\n\r\n3\r\n\r\n\r\n\r\n141237\r\n\r\n\r\n\r\n27in FHD Monitor\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n149.99\r\n\r\n\r\n\r\n01/05/19 20:33\r\n\r\n\r\n\r\n738 10th St, Los Angeles, CA 90001\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n149.99\r\n\r\n\r\n\r\nLos Angeles\r\n\r\n\r\n\r\n4\r\n\r\n\r\n\r\n141238\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n01/25/19 11:59\r\n\r\n\r\n\r\n387 10th St, Austin, TX 73301\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\nAustin\r\n\r\n\r\n’\r\n\r\nCreating a new variable that contains info for cities grouped\r\n\r\nbest_city=df.groupby([\"City\"]).sum()\r\nbest_city.reset_index(inplace=True)\r\n\r\nPlotting the data\r\n\r\nsns.barplot(x=\"Total_Sales\", y=\"City\", data=best_city);\r\nplt.show()\r\n\r\n\r\nThe city which had the highest number of sales was San Francisco\r\nQuestion 3: What time we should display the advertisements to maxime the likelihood of customer’s buying products?\r\nChanging the datetype to datetime to be able to extract the hour\r\n\r\ndf[\"Order Date\"]=pd.to_datetime(df[\"Order Date\"])\r\ndf[\"Hour\"]=df[\"Order Date\"].dt.hour\r\n\r\nCreating a new variable the contains the info about hour grouped\r\n\r\nhour=df.groupby(\"Hour\").sum()\r\nhour.reset_index(inplace=True)\r\n\r\nPlotting using seaborn\r\n\r\nsns.lineplot(data=hour, x=\"Hour\", y=\"Total_Sales\");\r\nplt.xticks(hour[\"Hour\"]);\r\nplt.grid();\r\nplt.show()\r\n\r\n\r\nThe best time to display the advertisements is 19h (7 pm). My assumption that this occurs because it when people have already came back from work and they are having dinner at this moment, watching TV.\r\nQuestion 4: What products are most often sold together?\r\nThe products are sold together when they have the same order ID, therefore we need only the row that have the same number for Order ID, and we’ll assign it to a new dataframe\r\n\r\nproducts=df[df[\"Order ID\"].duplicated(keep=False)]\r\nproducts_head=products.head()\r\nproducts_head.to_html()\r\n’\r\n\r\n\r\n\r\n\r\nOrder ID\r\n\r\n\r\n\r\nProduct\r\n\r\n\r\n\r\nQuantity Ordered\r\n\r\n\r\n\r\nPrice Each\r\n\r\n\r\n\r\nOrder Date\r\n\r\n\r\n\r\nPurchase Address\r\n\r\n\r\n\r\nMonth\r\n\r\n\r\n\r\nTotal_Sales\r\n\r\n\r\n\r\nCity\r\n\r\n\r\n\r\nHour\r\n\r\n\r\n\r\n41\r\n\r\n\r\n\r\n141275\r\n\r\n\r\n\r\nUSB-C Charging Cable\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n11.95\r\n\r\n\r\n\r\n2019-01-07 16:06:00\r\n\r\n\r\n\r\n610 Walnut St, Austin, TX 73301\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n11.95\r\n\r\n\r\n\r\nAustin\r\n\r\n\r\n\r\n16\r\n\r\n\r\n\r\n42\r\n\r\n\r\n\r\n141275\r\n\r\n\r\n\r\nWired Headphones\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\n2019-01-07 16:06:00\r\n\r\n\r\n\r\n610 Walnut St, Austin, TX 73301\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n11.99\r\n\r\n\r\n\r\nAustin\r\n\r\n\r\n\r\n16\r\n\r\n\r\n\r\n57\r\n\r\n\r\n\r\n141290\r\n\r\n\r\n\r\nApple Airpods Headphones\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n150.00\r\n\r\n\r\n\r\n2019-01-02 08:25:00\r\n\r\n\r\n\r\n4 1st St, Los Angeles, CA 90001\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n150.00\r\n\r\n\r\n\r\nLos Angeles\r\n\r\n\r\n\r\n8\r\n\r\n\r\n\r\n58\r\n\r\n\r\n\r\n141290\r\n\r\n\r\n\r\nAA Batteries (4-pack)\r\n\r\n\r\n\r\n3.0\r\n\r\n\r\n\r\n3.84\r\n\r\n\r\n\r\n2019-01-02 08:25:00\r\n\r\n\r\n\r\n4 1st St, Los Angeles, CA 90001\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n11.52\r\n\r\n\r\n\r\nLos Angeles\r\n\r\n\r\n\r\n8\r\n\r\n\r\n\r\n133\r\n\r\n\r\n\r\n141365\r\n\r\n\r\n\r\nVareebadd Phone\r\n\r\n\r\n\r\n1.0\r\n\r\n\r\n\r\n400.00\r\n\r\n\r\n\r\n2019-01-10 11:19:00\r\n\r\n\r\n\r\n20 Dogwood St, New York City, NY 10001\r\n\r\n\r\n\r\nJanuary\r\n\r\n\r\n\r\n400.00\r\n\r\n\r\n\r\nNew York City\r\n\r\n\r\n\r\n11\r\n\r\n\r\n’\r\n\r\nNow, we’ll join the produts which has the same order ID (grouped) and we’ll create a new column. After that, we’ll remove the duplicates\r\n\r\nproducts[\"Grouped\"]=products.groupby(\"Order ID\")[\"Product\"].transform(lambda x:', '.join(x))\r\n<string>:1: SettingWithCopyWarning: \r\nA value is trying to be set on a copy of a slice from a DataFrame.\r\nTry using .loc[row_indexer,col_indexer] = value instead\r\n\r\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\r\nproducts=products[[\"Order ID\", \"Grouped\"]].drop_duplicates()\r\n\r\nHere we’ll iterate the column Grouped to combine the values that has the same info in their row\r\n\r\ncount=Counter()\r\nfor row in products[\"Grouped\"]:\r\n    row_list=row.split(',')\r\n    count.update(Counter(combinations(row_list,2)))\r\n    \r\nfor key,value in count.most_common(1):\r\n    print(\"Produts that are more often sold together are:\", key)\r\nProduts that are more often sold together are: ('iPhone', ' Lightning Charging Cable')\r\n\r\nQuestion 5: What product sold the most? Why do you think it sold the most?\r\nTo find this answer we need to create a new variable and assign the product column grouped\r\n\r\nsold_most1=df.groupby(\"Product\")[\"Quantity Ordered\"].sum()\r\nsold_most=pd.DataFrame(data=sold_most1) # Creating a dataframe \r\nsold_most.reset_index(inplace=True)\r\nsold_most=sold_most.sort_values(by='Quantity Ordered',ascending=False)\r\nsold_most.iloc[0] # Answer\r\nProduct             AAA Batteries (4-pack)\r\nQuantity Ordered                   31017.0\r\nName: 5, dtype: object\r\n\r\nPlotting in sns\r\n\r\nsns.barplot(x=\"Quantity Ordered\",y=\"Product\",data=sold_most,palette='rocket');\r\nplt.show()\r\n\r\n\r\nPlotting in plt\r\n\r\nplt.bar(sold_most[\"Product\"],sold_most[\"Quantity Ordered\"]);\r\nplt.xticks(sold_most[\"Product\"],rotation='vertical');\r\nplt.show()\r\n\r\n\r\nThe AAA Batteries are the most sold product. My hypothesis it is because they are very cheap product. Lets confirm or not this statement\r\nLets create a new dataframe with the mean values of the product prices\r\n\r\n\r\ncheap1=df.groupby(\"Product\")[\"Price Each\"].mean()\r\ncheap=pd.DataFrame(data=cheap1)\r\ncheap.reset_index(inplace=True)\r\ncheap\r\n                       Product  Price Each\r\n0                 20in Monitor      109.99\r\n1       27in 4K Gaming Monitor      389.99\r\n2             27in FHD Monitor      149.99\r\n3       34in Ultrawide Monitor      379.99\r\n4        AA Batteries (4-pack)        3.84\r\n5       AAA Batteries (4-pack)        2.99\r\n6     Apple Airpods Headphones      150.00\r\n7   Bose SoundSport Headphones       99.99\r\n8                Flatscreen TV      300.00\r\n9                 Google Phone      600.00\r\n10                    LG Dryer      600.00\r\n11          LG Washing Machine      600.00\r\n12    Lightning Charging Cable       14.95\r\n13          Macbook Pro Laptop     1700.00\r\n14             ThinkPad Laptop      999.99\r\n15        USB-C Charging Cable       11.95\r\n16             Vareebadd Phone      400.00\r\n17            Wired Headphones       11.99\r\n18                      iPhone      700.00\r\n\r\nNow, we’ll merge those both dataframe to create a visualization plot with both y axes\r\n\r\nmerg=pd.merge(sold_most,cheap,how='inner')\r\n\r\nPlotting\r\n\r\nsns.barplot(x=\"Product\",y=\"Quantity Ordered\",data=merg);\r\nplt.xticks(rotation=90);\r\nax2 = plt.twinx();\r\nsns.lineplot(x=\"Product\",y=\"Price Each\",data=merg, color=\"b\", ax=ax2);\r\nplt.show()\r\n\r\n\r\nConclusions\r\nOn this analysis we can conclude:\r\nThe best month of sales in December, most likely because of the holidays on the end of the year;\r\nThe city which had the highest number of sales is San Francisco;\r\nThe best time to display our marketing campaign is on 19h (7 pm);\r\nThe products that are more often sold together are IPhone and Lightning Charging Cable;\r\nAAA batteries is the product that sold the most during the year, this happened because it is one of are chepaest products in store.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-03-20T10:33:11-07:00"
    }
  ],
  "collections": []
}
